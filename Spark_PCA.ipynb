{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Machine Learning\n",
    "## Exemplo com PCA no PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o exemplo de utilização das Bibliotecas de Machine Learning com o Spark, ciramos um modelo com redução de dimensionalidade através da Análise de Componentes Principais (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega bibliotecas base e inicia sessão:\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "ss = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('MLModels') \\\n",
    "                    .getOrCreate()\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega bibliotecas para tratamento de dados\n",
    "# e Machine Learning:\n",
    "from pyspark.ml.feature import PCA # Biblioteca para PCA. \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mfr</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>fiber</th>\n",
       "      <th>carbo</th>\n",
       "      <th>sugars</th>\n",
       "      <th>potass</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Golden_Grahams</td>\n",
       "      <td>G</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name mfr  calories  protein  fat  sodium  fiber  carbo  sugars  \\\n",
       "5  Golden_Grahams   G       110        1    1     280    0.0   15.0       9   \n",
       "\n",
       "   potass rating  \n",
       "5      45      A  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicia leitura de dados e criação\n",
    "# de DataFrames usando Pandas:\n",
    "cereal = pd.read_csv(\"/home/centos/spark-notebooks/Aula/PCA.csv\", sep = ';', header=0)\n",
    "cereal.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>fiber</th>\n",
       "      <th>carbo</th>\n",
       "      <th>sugars</th>\n",
       "      <th>potass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Just_Right_Crunchy__Nuggets</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  calories  protein  fat  sodium  fiber  carbo  \\\n",
       "28  Just_Right_Crunchy__Nuggets       110        2    1     170    1.0   17.0   \n",
       "\n",
       "    sugars  potass  \n",
       "28       6      60  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpa dataframe para conversão:\n",
    "cereal = cereal.drop(['mfr', 'rating'], axis = 1) # Remove qualitativas\n",
    "cereal.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte pandas DF para Spark DF:\n",
    "sp_cereal =  ss.createDataFrame(cereal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------+---+------+-----+-----+------+------+\n",
      "|                name|calories|protein|fat|sodium|fiber|carbo|sugars|potass|\n",
      "+--------------------+--------+-------+---+------+-----+-----+------+------+\n",
      "|        Cap'n'Crunch|     120|      1|  2|   220|  0.0| 12.0|    12|    35|\n",
      "|Cinnamon_Toast_Cr...|     120|      1|  3|   210|  0.0| 13.0|     9|    45|\n",
      "|    Honey_Graham_Ohs|     120|      1|  2|   220|  1.0| 12.0|    11|    45|\n",
      "|       Count_Chocula|     110|      1|  1|   180|  0.0| 12.0|    13|    65|\n",
      "|         Cocoa_Puffs|     110|      1|  1|   180|  0.0| 12.0|    13|    55|\n",
      "+--------------------+--------+-------+---+------+-----+-----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Amostra de dados:\n",
    "sp_cereal.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o correto funcionamento da PCA no Spark, as colunas para cada atributo ou 'feature' precisam ser convertidas em vetores separados. Isso pode ser realizado utilizando o método de transformação \"VectorAssembler\", conforme é demonstrado abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calories', 'protein', 'fat', 'sodium', 'fiber', 'carbo', 'sugars', 'potass']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separa vetores para PCA no Spark\n",
    "colunas = sp_cereal.drop('name').columns\n",
    "colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------------------------+\n",
      "|name                 |properties                              |\n",
      "+---------------------+----------------------------------------+\n",
      "|Cap'n'Crunch         |[120.0,1.0,2.0,220.0,0.0,12.0,12.0,35.0]|\n",
      "|Cinnamon_Toast_Crunch|[120.0,1.0,3.0,210.0,0.0,13.0,9.0,45.0] |\n",
      "|Honey_Graham_Ohs     |[120.0,1.0,2.0,220.0,1.0,12.0,11.0,45.0]|\n",
      "|Count_Chocula        |[110.0,1.0,1.0,180.0,0.0,12.0,13.0,65.0]|\n",
      "|Cocoa_Puffs          |[110.0,1.0,1.0,180.0,0.0,12.0,13.0,55.0]|\n",
      "+---------------------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria objetos SPARK necessários para PCA:\n",
    "assembler = VectorAssembler(inputCols=colunas, outputCol = 'properties')\n",
    "output_dat = assembler.transform(sp_cereal).select('name', 'properties')\n",
    "output_dat.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir resultados corretos, os dados no para o modelo PCA no Python/PySpark precisam ser escalados e normalizados. Os processos de centralização e normalização da biblioteca 'pyspark.ml.feature' abaixo servem para isso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name|    scaledProperties|\n",
      "+--------------------+--------------------+\n",
      "|        Cap'n'Crunch|[13.1168831168831...|\n",
      "|Cinnamon_Toast_Cr...|[13.1168831168831...|\n",
      "|    Honey_Graham_Ohs|[13.1168831168831...|\n",
      "|       Count_Chocula|[3.11688311688313...|\n",
      "|         Cocoa_Puffs|[3.11688311688313...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Centralizar dados:\n",
    "scaler = StandardScaler(inputCol=\"properties\", outputCol=\"scaledProperties\", withStd=False, withMean=True)\n",
    "\n",
    "# Estatisticas para modelo:\n",
    "scalerModel = scaler.fit(output_dat)\n",
    "\n",
    "# Normaliza propriedades:\n",
    "scaledData = scalerModel.transform(output_dat)\n",
    "scaledData.select(['name', 'scaledProperties']).show(5, truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados convertidos no formato adequado ao Spark e devidamente normalizados, podemos iniciar a construção dos componentes principais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de Componentes Principais:\n",
    "pca = PCA(k=3, inputCol = scaler.getOutputCol(), outputCol=\"pca_properties\")\n",
    "model = pca.fit(scaledData)\n",
    "\n",
    "transformed_property = model.transform(scaledData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a construção do modelo, identificamos a variância utilizada para a separação dos componentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.54, 40.44,  2.79])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(100.00*model.explainedVariance.toArray(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos listar e classificar as propriedades nutricionais de acordo com suas correlações com componentes identificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>calories</th>\n",
       "      <td>-0.0741</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protein</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>-0.9919</td>\n",
       "      <td>-0.1026</td>\n",
       "      <td>-0.0734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiber</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>-0.0299</td>\n",
       "      <td>-0.0291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbo</th>\n",
       "      <td>-0.0197</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugars</th>\n",
       "      <td>-0.0057</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potass</th>\n",
       "      <td>0.1012</td>\n",
       "      <td>-0.9940</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1     PC2     PC3\n",
       "calories -0.0741  0.0090  0.9864\n",
       "protein   0.0013 -0.0083  0.0036\n",
       "fat       0.0002 -0.0027  0.0288\n",
       "sodium   -0.9919 -0.1026 -0.0734\n",
       "fiber     0.0043 -0.0299 -0.0291\n",
       "carbo    -0.0197  0.0185  0.0259\n",
       "sugars   -0.0057 -0.0020  0.1374\n",
       "potass    0.1012 -0.9940  0.0175"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificação dos Componentes:\n",
    "componentes = np.round(model.pc.toArray(), 4)\n",
    "df_pc = pd.DataFrame(componentes, columns = ['PC1', 'PC2', 'PC3'], index = colunas)\n",
    "df_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em conclusão, o exemplo acima demonstra as capacidades dos algoritmos de Machine Learning disponíveis no Spark. Podemos observar que suas capacidades são similares aos algoritmos de Machine Learning do Python e R, mas a estrutura dos objetos do Spark (RDD e DataFrames) exigem um tratamento peculiar aos dados antes de submeter aos testes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
